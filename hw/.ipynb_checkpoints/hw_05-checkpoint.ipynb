{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5\n",
    "\n",
    "Covers Lectures 17, 21."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Problem 1: Calibrating the reaction rates $\\kappa$ [0-4] in Catalytic Conversion of Nitrate to Nitrogen\n",
    "\n",
    "This is Example 3.1 of [(Tsilifis, 2014)](http://arxiv.org/abs/1410.5522).\n",
    "\n",
    "Consider the catalytic\n",
    "conversion of nitrate ($\\mbox{NO}_3^-$) to nitrogen ($\\mbox{N}_2$) and other\n",
    "by-products by electrochemical means.\n",
    "The mechanism that is followed is complex and not well understood.\n",
    "The experiment of \\cite{katsounaros} confirmed the\n",
    "production of nitrogen ($\\mbox{N}_2$), ammonia\n",
    "($\\mbox{NH}_3$), and nitrous oxide ($\\mbox{N}_2\\mbox{O}$) as final products\n",
    "of the reaction, as well as the intermediate production of nitrite ($\\mbox{NO}_2^-$).\n",
    "The data are reproduced in [Comma-separated values](https://en.wikipedia.org/wiki/Comma-separated_values) (CSV) and stored in\n",
    "[data/catalysis.csv](data/catalysis.csv).\n",
    "The time is measured in minutes and the conentrations are measured in $\\mbox{mmol}\\cdot\\mbox{L}^{-1}$.\n",
    "Let's load the data into this notebook using the [Pandas](http://pandas.pydata.org) Python module:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NO3</th>\n",
       "      <th>NO2</th>\n",
       "      <th>N2</th>\n",
       "      <th>NH3</th>\n",
       "      <th>N2O</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>250.95</td>\n",
       "      <td>107.32</td>\n",
       "      <td>18.51</td>\n",
       "      <td>3.33</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>123.66</td>\n",
       "      <td>132.33</td>\n",
       "      <td>74.85</td>\n",
       "      <td>7.34</td>\n",
       "      <td>20.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>84.47</td>\n",
       "      <td>98.81</td>\n",
       "      <td>166.19</td>\n",
       "      <td>13.14</td>\n",
       "      <td>42.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>30.24</td>\n",
       "      <td>38.74</td>\n",
       "      <td>249.78</td>\n",
       "      <td>19.54</td>\n",
       "      <td>55.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>27.94</td>\n",
       "      <td>10.42</td>\n",
       "      <td>292.32</td>\n",
       "      <td>24.07</td>\n",
       "      <td>60.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>13.54</td>\n",
       "      <td>6.11</td>\n",
       "      <td>309.50</td>\n",
       "      <td>27.26</td>\n",
       "      <td>62.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         NO3     NO2      N2    NH3    N2O\n",
       "Time                                      \n",
       "0     500.00    0.00    0.00   0.00   0.00\n",
       "30    250.95  107.32   18.51   3.33   4.98\n",
       "60    123.66  132.33   74.85   7.34  20.14\n",
       "90     84.47   98.81  166.19  13.14  42.10\n",
       "120    30.24   38.74  249.78  19.54  55.98\n",
       "150    27.94   10.42  292.32  24.07  60.65\n",
       "180    13.54    6.11  309.50  27.26  62.54"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "catalysis_data = pd.read_csv('../data/catalysis.csv', index_col=0)\n",
    "catalysis_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The theory of catalytic reactions guarantees that the total mass must be conserved.\n",
    "However, this is not the case in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time\n",
       "0      500.00\n",
       "30     385.09\n",
       "60     358.32\n",
       "90     404.71\n",
       "120    394.28\n",
       "150    415.40\n",
       "180    418.95\n",
       "dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalysis_data.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This inconsistency suggests the existence of an intermediate unobserved reaction product X.\n",
    "[(Katsounaros, 2012)](http://www.sciencedirect.com/science/article/pii/S0013468612005208) suggested that the following reaction path shown in the following figure.\n",
    "\n",
    "![](../lectures/figures/scheme.png \"Reaction Scheme\")\n",
    "\n",
    "The dynamical system associated with the reaction is:\n",
    "$$\n",
    "\\begin{array}{cc}\n",
    "\\frac{d \\left[\\mbox{NO}_3^-\\right]}{dt} &= -k_1\\left[\\mbox{NO}_3^-\\right], \\\\\n",
    "\\frac{d\\left[\\mbox{NO}_2^-\\right]}{dt} &= k_1\\left[\\mbox{NO}_3^-\\right] - (k_2 + k_4 +\n",
    "k_5)[\\mbox{NO}_2^-], \\\\\n",
    "\\frac{d \\left[\\mbox{X}\\right]}{dt} &= k_2 \\left[\\mbox{NO}_2^-\\right] - k_3 [X],\\\\\n",
    "\\frac{d \\left[\\mbox{N}_2\\right]}{dt} &= k_3 \\left[\\mbox{X}\\right], \\\\\n",
    "\\frac{d \\left[\\mbox{NH}_3\\right]}{dt} &= k_4 \\left[\\mbox{NO}_2^-\\right],\\\\\n",
    "\\frac{d \\left[\\mbox{N}_2O\\right]}{dt} &= k_5 \\left[\\mbox{NO}_2^-\\right],\n",
    "\\end{array}\n",
    "$$\n",
    "where $[\\cdot]$ denotes the concentration of a quantity, and\n",
    "$k_i > 0$, $i=1,...5$ are the *kinetic rate constants*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions - Calibrate the reaction rates $\\kappa=(\\kappa_1,\\kappa_2,\\kappa_3,\\kappa_4,\\kappa_5)$ in the Catalysis Model to the Experimental Data\n",
    "\n",
    "Assume that you are a chemical engineer and that you are assigned the task of designing a reactor for the conversion of nitrate to nitrogen. Before you start designing, you are asked to calibrate the reaction rates $\\kappa_1,\\kappa_2,\\kappa_3,\\kappa_4,\\kappa_5$ using the observed concentration $y=(y_1,...,y_5)$ at $t=180$ stored in [data/catalysis.csv](data/catalysis.csv).\n",
    "\n",
    "We wish to calibrate the reaction rate parameters of the model to the data. Because the parameters are two small, it is desired to work with the transformed version:\n",
    "\n",
    "$$\n",
    "\\xi_i = \\log\\left(180k_i\\right).\n",
    "$$\n",
    "\n",
    "You are requested to address this problem by using the following two appeoaches:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach (1) Use Bayesian inversion method to inverse the reaction rates $\\kappa=(\\kappa_1,\\kappa_2,\\kappa_3,\\kappa_4,\\kappa_5)$ using Bayesian inference and MCMC.\n",
    "\n",
    "We assume that the observed consentration value $y=(y_1,...,y_5)$ is contaminated with (additive) noise $\\epsilon_y$ with unknown scale $\\sigma_y^2$ , in log scale; i.e.\n",
    "\n",
    "$$ \\log(y) = \\log(u(\\xi)) + \\epsilon, \\  \\epsilon \\sim \\text{N}(0,\\sigma_y^2), $$ \n",
    "\n",
    "where $u(\\xi)$ is the free of errors consentration function with respect to the reaction rates $\\kappa=(\\kappa_1,\\kappa_2,\\kappa_3,\\kappa_4,\\kappa_5)$, but free of errors.\n",
    "\n",
    "For a given value of $\\xi=(\\xi_1, \\xi_2, \\xi_3 \\xi_4, \\xi_5)$, the consentration function $u(\\xi)$ can be computed by running the Computer Model described; see Section `Computer Model' for details.\n",
    "\n",
    "Therefore, \n",
    "\n",
    "##### Statistical model   $\\mathcal{L}(y|\\xi,\\sigma_y^2)$\n",
    "\n",
    "The likelihood function is:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(y|\\xi,\\sigma_y^2) = \\prod_{i=1}^{n=5}\\text{LN}(y_i|\\log(u(\\xi_i)),\\sigma_y^2)\\ \n",
    "$$\n",
    "\n",
    "where $\\text{LN}(\\mu,\\sigma^2)$ denotes the the Log-Normal distribution with location paremeter $\\mu$, and scale parameter $\\sigma^2$. \n",
    "\n",
    "(Note: $X\\sim \\text{LN}(\\mu,\\sigma^2)$ iff $\\log(X)\\sim \\text{N}(\\mu,\\sigma^2)$).\n",
    "\n",
    "##### Prior model   $\\pi(\\xi_1, \\xi_2, \\xi_3 \\xi_4, \\xi_5, \\sigma^2)$\n",
    "\n",
    "To account for uncertainty about the unknown reaction rates $\\xi$, we assign priors:\n",
    "\n",
    "$$\n",
    "\\xi_1 \\sim \\text{N}(\\mu_1=1.35, \\sigma_1^2 = 0.05^2), \\   \\xi_1 \\in (-\\infty, +\\infty)\n",
    "$$\n",
    "$$\n",
    "\\xi_2 \\sim \\text{N}(\\mu_2=1.65, \\sigma_2^2 = 0.08^2), \\   \\xi_2 \\in (-\\infty, +\\infty)\n",
    "$$\n",
    "$$\n",
    "\\xi_3 \\sim \\text{N}(\\mu_3=1.34, \\sigma_3^2 = 0.11^2), \\   \\xi_3 \\in (-\\infty, +\\infty)\n",
    "$$\n",
    "$$\n",
    "\\xi_4 \\sim \\text{N}(\\mu_4=-0.16, \\sigma_4^2 = 0.16^2), \\   \\xi_4 \\in (-\\infty, +\\infty)\n",
    "$$\n",
    "$$\n",
    "\\xi_5 \\sim \\text{N}(\\mu_5=-3.84, \\sigma_5^2 = 0.20^2), \\   \\xi_5 \\in (-\\infty, +\\infty)\n",
    "$$\n",
    "\n",
    "To account for uncertainty about the unknown scale of the noise term, we assign prior:\n",
    "\n",
    "$$\n",
    "\\sigma_y^2 \\sim \\text{IG}(a_{\\sigma_y^2}=0.001, b_{\\sigma_y^2}=0.001), \\   \\sigma_y^2>0\n",
    "$$\n",
    "with density\n",
    "$$\n",
    "\\text{IG}(x|\\alpha, \\beta) = \n",
    "\\begin{cases}\n",
    "\\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} x^{-\\alpha - 1} \\exp \\left(\\frac{-\\beta}{x}\\right) & \\text{, if } x > 0 \\\\\n",
    "0 & \\text{, otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "##### The Bayesian model (synopsis)\n",
    "\n",
    "$$\n",
    "\\begin{array}{rl}\n",
    "y \\sim & \\text{LN}(y_i|\\log(u(\\xi_i)),\\sigma_y^2) \\  i=1,...,5 \\\\\n",
    "\\xi_1 \\sim & \\text{N}(\\mu_1=1.35, \\sigma_1^2 = 0.05^2), \\\\\n",
    "\\xi_2 \\sim & \\text{N}(\\mu_2=1.65, \\sigma_2^2 = 0.08^2), \\\\\n",
    "\\xi_3 \\sim & \\text{N}(\\mu_3=1.34, \\sigma_3^2 = 0.11^2), \\\\\n",
    "\\xi_4 \\sim & \\text{N}(\\mu_4=-0.16, \\sigma_4^2 = 0.16^2), \\\\\n",
    "\\xi_5 \\sim & \\text{N}(\\mu_5=-3.84, \\sigma_5^2 = 0.20^2), \\\\\n",
    "\\sigma_y^2 \\sim & \\text{IG}(a_{\\sigma_y^2}=0.001, b_{\\sigma_y^2}=0.001),\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "##### Posterior model $\\pi(\\xi_1, \\xi_2, \\xi_3, \\xi_4, \\xi_5, \\sigma^2|y)$\n",
    "\n",
    "The posterior distribution is given via the Bayes theorem as:\n",
    "\n",
    "$$\n",
    "\\begin{array}{rl}\n",
    "\\pi(\\xi_1,\\xi_2,\\xi_3,\\xi_4,\\xi_5,\\sigma_y^2|y) \\propto& \\mathcal{L}(y|\\xi,\\sigma_y^2) \\pi(\\xi_1, \\xi_2, \\xi_3 \\xi_4, \\xi_5, \\sigma^2) \\\\\n",
    "\\ \\propto & ...\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "##### Your tasks:\n",
    "\n",
    "1. Calculate the posterior distribution density up to an unknown normalising constant, a.k.a $\\pi(\\xi_1,\\xi_2,\\xi_3,\\xi_4,\\xi_5,\\sigma_y^2|y) \\propto ...$\n",
    "\n",
    "3. Design a Markov chain Monte Carlo sampler (in python) in order to sample from the posterior distribution $\\pi(\\xi_1, \\xi_2, \\xi_3 \\xi_4, \\xi_5, \\sigma^2|y)$. \n",
    "    1. Why did you design your MCMC sampler like that?\n",
    "        + Hint: Most of the MCMC schemes and Metropolis-Hastings algorithms presented in the lexture can be used, however some of them may be more preferable)\n",
    "\n",
    "4. Draw a sample from the posterior $\\pi(\\xi_1,\\xi_2,\\xi_3,\\xi_4,\\xi_5,\\sigma_y^2|y)$ via MCMC:\n",
    "    1. Generate a sample for $\\xi_1, \\xi_2, \\xi_3 \\xi_4, \\xi_5, \\sigma^2$ by simulating the MCMC sampler\n",
    "    2. Draw the trace plot of the generated MCMC sample for each indivudual variable $\\xi_1, \\xi_2, \\xi_3 \\xi_4, \\xi_5, \\sigma^2$\n",
    "    3. Report:\n",
    "        1. the scale parameter of the proposals if Random Walk Matropolis was used\n",
    "        2. the average acceptance probebilities, if any kind of Metropolis-Hastings alg. were used\n",
    "        3. the integrated autocorrelation times of the generated sample for each indivudual variable $\\xi_1, \\xi_2, \\xi_3 \\xi_4, \\xi_5, \\sigma^2$\n",
    "            + Hint: for example, use the function iat() (in python) provided below\n",
    "    3. Draw the autocorrelation plots of the generated sample for each indivudual variable $\\xi_1, \\xi_2, \\xi_3 \\xi_4, \\xi_5, \\sigma^2$. \n",
    "        + Hint: for example, use the function myacorr() (in python) provided below\n",
    "    4. Write down a short discussion and comments \n",
    "        + Does your MCMC sampler works satisfactory? Why ?\n",
    "\n",
    "4. Perform Bayesian inference on the unknown parameters $\\kappa_1,\\kappa_2,\\kappa_3,\\kappa_4,\\kappa_5, \\sigma^2$, by using the generated MCMC sample.         \n",
    "    (Hint: A transformation is required; recall that $\\xi_i=\\log(180\\kappa_i)$, $i=1,...,5$, so $\\kappa_i=...$)\n",
    "    1. Compute the posterior averages, (point estimates), of $\\kappa_1,\\kappa_2,\\kappa_3,\\kappa_4,\\kappa_5, \\sigma^2$, as well as the associated standard errors (s.e.).  \n",
    "        + Hint: the MCMC sample is not independent\n",
    "    2. Plot the estimated marginal posterior densities of the unknown parameters $\\kappa_1,\\kappa_2,\\kappa_3,\\kappa_4,\\kappa_5$. \n",
    "        + Hint, histogram is accepted as an estimator.\n",
    "    3. Plot 2D scatter-plots for every pair of the unknown parameters $\\kappa_1,\\kappa_2,\\kappa_3,\\kappa_4,\\kappa_5$. \n",
    "        + Hint: You can use ( pandas.tools.plotting import scatter_matrix )\n",
    "    4. Write down a short discussion and comments \n",
    "        + What conclusions can you draw from the posterior densities, scatter-plots, estimates, s.e. ??? \n",
    "\n",
    "5. Use Bayesian global optimization method to inverse the reaction rates $\\kappa=(\\kappa_1,\\kappa_2,\\kappa_3,\\kappa_4,\\kappa_5)$.\n",
    "Hint: use Bayesian global optimization toolbox - http://sheffieldml.github.io/GPyOpt/. Define and minimize an appropriate loss function, e.g., the L2-error between observations and model predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computer Model\n",
    "\n",
    "This section describes how to compute the function $u(\\xi)$, where $\\xi=(\\xi_1,...,\\xi_5)$, $\\xi_i=\\log(180\\kappa_i)$ for $i=1,...,5$, which is required for the computation of the likelihood function.\n",
    "\n",
    "We will develop a generic computational model for the solution of dynamical systems and we will use it to study the catalysis problem. The code relies on the [Fourth-order Runge-Kutta method](https://en.wikipedia.org/wiki/Runge–Kutta_methods) and is a modified copy of [http://www.math-cs.gordon.edu/courses/ma342/python/diffeq.py](http://www.math-cs.gordon.edu/courses/ma342/python/diffeq.py) developed by Jonathan Senning. The code solves:\n",
    "\n",
    "$$\n",
    "\\begin{array}{ccc}\n",
    "\\dot{\\mathbf{y}} &=& f(\\mathbf{y}, t),\\\\\n",
    "\\mathbf{y}(0) &=& \\mathbf{y}_0.\n",
    "\\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def rk45( f, y0, t, args=() ):\n",
    "    \"\"\"Fourth-order Runge-Kutta method with error estimate.\n",
    "\n",
    "    USAGE:\n",
    "        y = rk45(f, x0, t, args=())\n",
    "\n",
    "    INPUT:\n",
    "        f     - function of x and t equal to dx/dt.  x may be multivalued,\n",
    "                in which case it should a list or a NumPy array.  In this\n",
    "                case f must return a NumPy array with the same dimension\n",
    "                as x.\n",
    "        y0    - the initial condition(s).  Specifies the value of x when\n",
    "                t = t[0].  Can be either a scalar or a list or NumPy array\n",
    "                if a system of equations is being solved.\n",
    "        t     - list or NumPy array of t values to compute solution at.\n",
    "                t[0] is the the initial condition point, and the difference\n",
    "                h=t[i+1]-t[i] determines the step size h.\n",
    "        args  - any other parameters of the function f.\n",
    "\n",
    "    OUTPUT:\n",
    "        y     - NumPy array containing solution values corresponding to each\n",
    "                entry in t array.  If a system is being solved, x will be\n",
    "                an array of arrays.\n",
    "\n",
    "    NOTES:\n",
    "        This version is based on the algorithm presented in \"Numerical\n",
    "        Mathematics and Computing\" 6th Edition, by Cheney and Kincaid,\n",
    "        Brooks-Cole, 2008.\n",
    "    \"\"\"\n",
    "\n",
    "    # Coefficients used to compute the independent variable argument of f\n",
    "\n",
    "    c20  =   2.500000000000000e-01  #  1/4\n",
    "    c30  =   3.750000000000000e-01  #  3/8\n",
    "    c40  =   9.230769230769231e-01  #  12/13\n",
    "    c50  =   1.000000000000000e+00  #  1\n",
    "    c60  =   5.000000000000000e-01  #  1/2\n",
    "\n",
    "    # Coefficients used to compute the dependent variable argument of f\n",
    "\n",
    "    c21 =   2.500000000000000e-01  #  1/4\n",
    "    c31 =   9.375000000000000e-02  #  3/32\n",
    "    c32 =   2.812500000000000e-01  #  9/32\n",
    "    c41 =   8.793809740555303e-01  #  1932/2197\n",
    "    c42 =  -3.277196176604461e+00  # -7200/2197\n",
    "    c43 =   3.320892125625853e+00  #  7296/2197\n",
    "    c51 =   2.032407407407407e+00  #  439/216\n",
    "    c52 =  -8.000000000000000e+00  # -8\n",
    "    c53 =   7.173489278752436e+00  #  3680/513\n",
    "    c54 =  -2.058966861598441e-01  # -845/4104\n",
    "    c61 =  -2.962962962962963e-01  # -8/27\n",
    "    c62 =   2.000000000000000e+00  #  2\n",
    "    c63 =  -1.381676413255361e+00  # -3544/2565\n",
    "    c64 =   4.529727095516569e-01  #  1859/4104\n",
    "    c65 =  -2.750000000000000e-01  # -11/40\n",
    "\n",
    "    # Coefficients used to compute 4th order RK estimate\n",
    "\n",
    "    a1  =   1.157407407407407e-01  #  25/216\n",
    "    a2  =   0.000000000000000e-00  #  0\n",
    "    a3  =   5.489278752436647e-01  #  1408/2565\n",
    "    a4  =   5.353313840155945e-01  #  2197/4104\n",
    "    a5  =  -2.000000000000000e-01  # -1/5\n",
    "\n",
    "    b1  =   1.185185185185185e-01  #  16.0/135.0\n",
    "    b2  =   0.000000000000000e-00  #  0\n",
    "    b3  =   5.189863547758284e-01  #  6656.0/12825.0\n",
    "    b4  =   5.061314903420167e-01  #  28561.0/56430.0\n",
    "    b5  =  -1.800000000000000e-01  # -9.0/50.0\n",
    "    b6  =   3.636363636363636e-02  #  2.0/55.0\n",
    "\n",
    "    n = len( t )\n",
    "    y = np.array( [ y0 ] * n )\n",
    "    for i in xrange( n - 1 ):\n",
    "        h = t[i+1] - t[i]\n",
    "        k1 = h * f( y[i], t[i], *args )\n",
    "        k2 = h * f( y[i] + c21 * k1, t[i] + c20 * h, *args )\n",
    "        k3 = h * f( y[i] + c31 * k1 + c32 * k2, t[i] + c30 * h, *args )\n",
    "        # BUG: The ``-`` in the equation below should be a ``+``.\n",
    "        k4 = h * f( y[i] + c41 * k1 + c42 * k2 + c43 * k3, t[i] + c40 * h, *args )\n",
    "        k5 = h * f( y[i] + c51 * k1 + c52 * k2 + c53 * k3 + c54 * k4, \\\n",
    "                        t[i] + h, *args )\n",
    "        k6 = h * f( \\\n",
    "            y[i] + c61 * k1 + c62 * k2 + c63 * k3 + c64 * k4 + c65 * k5, \\\n",
    "            t[i] + c60 * h, *args )\n",
    "\n",
    "        y[i+1] = y[i] + a1 * k1 + a3 * k3 + a4 * k4 + a5 * k5\n",
    "        y5 = y[i] + b1 * k1 + b3 * k3 + b4 * k4 + b5 * k5 + b6 * k6\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following we will develop a solver for the catalysis model. All, we need to do is define the right hand side of Eq. (\\ref{eq:kinetic_model}):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_catalysis(y, t, kappa):\n",
    "    rhs = np.zeros((6,))\n",
    "    rhs[0] = -kappa[0] * y[0]\n",
    "    rhs[1] = kappa[0] * y[0] - (kappa[1] + kappa[3] + kappa[4]) * y[1]\n",
    "    rhs[2] = kappa[1] * y[1] - kappa[2] * y[2]\n",
    "    rhs[3] = kappa[2] * y[2]\n",
    "    rhs[4] = kappa[3] * y[1]\n",
    "    rhs[5] = kappa[4] * y[1]\n",
    "    return rhs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to calibrate the reaction rate parameters of the model to the data. Because the parameters are two small, let us work with the transformed version:\n",
    "\n",
    "$$\n",
    "\\xi_i = \\log\\left(180k_i\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the routine that returns $u(\\xi)$ for given values of $\\xi_1$, $\\xi_2$, $\\xi_3$, $\\xi_4$, $\\xi_5$ is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def comp_model(xi1, xi2, xi3, xi4, xi5):\n",
    "    t = np.linspace(0, 180, 100)\n",
    "    kappa = np.exp([xi1, xi2, xi3, xi4, xi5]) / 180.\n",
    "    y = rk45(f_catalysis, (500., 0., 0., 0., 0., 0.), t, args=(kappa,))\n",
    "    return np.array([y[-1,0],y[-1,1],y[-1,3],y[-1,4],y[-1,5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary routines for the computation of the integrated autocorrelation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# AUXILIARY FUNCTIONS FOR THE COMPUTATION OF HE AUTOCORRELATIONS\n",
    "# ===============================================================\n",
    "\n",
    "import numpy as np\n",
    "from scipy.linalg import toeplitz\n",
    "# from __future__ import division, absolute_import, print_function\n",
    "\n",
    "def myacorr(x) :\n",
    "    mean_x = x.mean()\n",
    "    z = np.fft.fft( x-mean_x, int(2**np.ceil( np.log2(2*x.size) ))+1 )\n",
    "    z = z.real**2 + z.imag**2\n",
    "    z = np.fft.ifft( z ).real\n",
    "    z = z[:x.size]\n",
    "    z = z/z[0]\n",
    "    return z\n",
    "\n",
    "# from __future__ import division, absolute_import, print_function\n",
    "from scipy.linalg import toeplitz\n",
    "\n",
    "def iat(x):\n",
    "    r\"\"\"Estimate the integrated autocorrelation time, :math:`\\tau_{int}` of a\n",
    "    time series.\n",
    "\n",
    "    This method estimates the spectral density at zero frequency by fitting\n",
    "    an AR(p) model, with p selected by AIC.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : ndarray, shape=(n_samples, n_dims)\n",
    "        The time series, with time along axis 0.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Plummer, M., Best, N., Cowles, K., and Vines, K. (2006). CODA:\n",
    "        Convergence diagnosis and output analysis for MCMC. R News, 6(1):7-11.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tau_int : ndarray, shape=(n_dims,)\n",
    "        The estimated integrated autocorrelation time of each dimension in\n",
    "        ``x``, considered independently.\n",
    "    \"\"\"\n",
    "    if x.ndim == 1:\n",
    "        x = x.reshape(-1, 1)\n",
    "    process_var = np.var(x, axis=0, ddof=1)\n",
    "\n",
    "    tau_int = np.zeros(x.shape[1])\n",
    "    for j in range(x.shape[1]):\n",
    "        # fit an AR(p) model, with p selected by AIC\n",
    "        rho, sigma2 = yule_walker(x[:,j], order_max=10)\n",
    "        # power spectral density at zero frequency\n",
    "        spec0 = sigma2 / (1 - np.sum(rho))**2\n",
    "        # divide by the variance\n",
    "        tau_int[j] = spec0 / process_var[j]\n",
    "\n",
    "    return tau_int\n",
    "\n",
    "def yule_walker(X, aic=True, order_max=None, demean=True):\n",
    "    \"\"\"Estimate AR(p) parameters from a sequence X using Yule-Walker equation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like\n",
    "        1d array\n",
    "    aic: bool\n",
    "        If ``True``, then the Akaike Information Criterion is used to choose\n",
    "        the order of the autoregressive model. If ``False``, the model of order\n",
    "        ``order.max`` is fitted.\n",
    "    order_max : integer, optional\n",
    "        Maximum order of model to fit. Defaults to the smaller of N-1 and\n",
    "        10*log10(N) where N is the length of the sequence.\n",
    "    demean : bool\n",
    "        True, the mean is subtracted from `X` before estimation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rho : array, shape=(order,)\n",
    "        The autoregressive coefficients\n",
    "    sigma2 : float\n",
    "        Variance of the nosie term\n",
    "    aic : float\n",
    "        Akaike Information Criterion\n",
    "    \"\"\"\n",
    "    # this code is adapted from https://github.com/statsmodels/statsmodels.\n",
    "    # changes are made to increase compability with R's ``ar.yw``.\n",
    "    X = np.array(X)\n",
    "    if demean:\n",
    "        X -= X.mean()\n",
    "    n = X.shape[0]\n",
    "\n",
    "    if X.ndim > 1 and X.shape[1] != 1:\n",
    "        raise ValueError(\"expecting a vector to estimate AR parameters\")\n",
    "\n",
    "    if order_max is None:\n",
    "        order_max = min(n - 1, int(10 * np.log10(n)))\n",
    "\n",
    "    r = np.zeros(order_max+1, np.float64)\n",
    "    r[0] = (X**2).sum() / n\n",
    "\n",
    "    for k in range(1, order_max+1):\n",
    "        r[k] = (X[0:-k]*X[k:]).sum() / n\n",
    "\n",
    "    orders = np.arange(1, order_max+1) if aic else [order_max]\n",
    "    aics = np.zeros(len(orders))\n",
    "    sigmasqs = np.zeros(len(orders))\n",
    "    rhos = [None for i in orders]\n",
    "\n",
    "    for i, order in enumerate(orders):\n",
    "        r_left = r[:order]\n",
    "        r_right = r[1:order+1]\n",
    "\n",
    "        # R = toeplitz(r[:-1])\n",
    "        R = toeplitz(r_left)\n",
    "        # rho = np.linalg.solve(R, r[1:])\n",
    "        rho = np.linalg.solve(R, r_right)\n",
    "        # sigmasq = r[0] - (r[1:]*rho).sum()\n",
    "        sigmasq = r[0] - (r_right*rho).sum()\n",
    "        aic = len(X) * (np.log(sigmasq) + 1) + 2*order + 2*demean\n",
    "        # R compability\n",
    "        sigmasq = sigmasq * len(X)/(len(X) - (order + 1))\n",
    "\n",
    "        aics[i] = aic\n",
    "        sigmasqs[i] = sigmasq\n",
    "        rhos[i] = rho\n",
    "\n",
    "    index = np.argmin(aics)\n",
    "    return rhos[index], sigmasqs[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution to the Bayesian approach: (Approach 1)\n",
    "\n",
    "Feel free to change the cell structure below ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The posterior distribution density, up to an unknown normalising constant is such that:\n",
    "\n",
    "$$\n",
    "\\begin{array}{rl}\n",
    "\\pi(\\xi_1,\\xi_2,\\xi_3,\\xi_4,\\xi_5,\\sigma_y^2|y) \\propto& \\mathcal{L}(y|\\xi,\\sigma_y^2) \\pi(\\xi_1, \\xi_2, \\xi_3, \\xi_4, \\xi_5, \\sigma^2) \\\\\n",
    "\\ \\propto & ...\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 (initialise the code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =====================\n",
    "# LAOD REQUIRED MODULES\n",
    "# =====================\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import pymc as pm\n",
    "import pandas as pd\n",
    "from ipywidgets import interactive\n",
    "import scipy as scipy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# OTEHR AUXILIARY FUNCTIONS REQUIRED\n",
    "# ==================================\n",
    "\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ================================\n",
    "# COMPUTER MODEL RELATED FUNCTIONS\n",
    "# ================================\n",
    "\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ============================\n",
    "# DEFINE THE POSTERIOR DENSITY\n",
    "# ============================\n",
    "\n",
    "# Define the posterior distribution density, \n",
    "#  up to a common normalising constant, \n",
    "#  and in the log scale (for computational stability)\n",
    "\n",
    "# Data\n",
    "import pandas as pd\n",
    "catalysis_data = pd.read_csv('../data/catalysis.csv', index_col=0)\n",
    "thedata = np.array(catalysis_data.values[6])\n",
    "\n",
    "# Log Posterior PDF up to an unknown normalising constant\n",
    "\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ================\n",
    "# THE MCMC SAMPLER\n",
    "# ================\n",
    "\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ========================\n",
    "# SAMPLE EXAMINATION\n",
    "# ========================\n",
    "\n",
    "# the average acceptance probebilities ...\n",
    "# the scale parameter of the proposals if Random Walk Matropolis was used ...\n",
    "# the integrated autocorrelation time for the generated sample ...\n",
    "\n",
    "#...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Trace plots of the sample\n",
    "# ========================\n",
    "\n",
    "#...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Autocorrelation plots\n",
    "# ========================\n",
    "\n",
    "#...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# TRANSFORMATION THE SAMPLE FROM $\\xi$ to $\\kappa$\n",
    "# ================================================\n",
    "\n",
    "#...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# Posterior expected values with standard errors\n",
    "# ================================================\n",
    "\n",
    "#...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# Marginal posterior densities of $\\kappa$, and $\\sigma_y^2$\n",
    "# ================================================\n",
    "\n",
    "#...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# Marginal posterior densities (Part 2, and pairwise scaterplots)\n",
    "# ================================================\n",
    "\n",
    "#....\n",
    "\n",
    "\n",
    "# HINT:\n",
    "# let's say the sample is stored in matrix mat \n",
    "# them\n",
    "# \n",
    "# from pandas.tools.plotting import scatter_matrix\n",
    "# from pandas import DataFrame\n",
    "# df = DataFrame(data=mat, columns=['k_1', 'k_2', 'k_3', 'k_4', 'k_5']) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "<mark> <b>The bib file biblio.bib was not found\n",
    "\n",
    "</b> </mark>(<a id=\"cit-katsounaros\" href=\"#call-katsounaros\">?</a>) !! _This reference was not found in biblio.bib _ !!\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
